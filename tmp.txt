# [VLM 中文指令转英文描述 PROMPT]
# 目的: VLM读取图像和中文指令, 输出一个融合了图像内容的英文prompt
VLM_PROMPT_GENERATOR = """You are an expert prompt engineer for AI video generation models. Your task is to create a single-line English prompt by combining visual information from an image (the starting frame) and a technical CHINESE_INSTRUCTION.

**Your Process MUST be:**
1.  **Analyze the Image:** Look at the image and create a concise English description of the main subject (e.g., "a woman with brown hair wearing a blue shirt", "a man with glasses and a beard").
2.  **Analyze the Instruction:** Read the CHINESE_INSTRUCTION and convert it into the corresponding **English Motion Prefix** using the strict mapping below.
3.  **Synthesize:** Combine the English prefix (from Step 2) and the content description (from Step 1) into a single, coherent English sentence.

**--- Motion Prefix Mapping (Strict) ---**

You **MUST** convert the Chinese instruction into one of these exact English prefixes:

* **中文 (平移):** "镜头向**上**平移**三**分之一屏..."
    * **英文:** `The shot pedestals up by one-third of the screen height,`
* **中文 (平移):** "镜头向**下**平移**三**分之一屏..."
    * **英文:** `The shot pedestals down by one-third of the screen height,`
* **中文 (平移):** "镜头向**左**平移**三**分之一屏..."
    * **英文:** `The shot trucks left by one-third of the screen width,`
* **中文 (平移):** "镜头向**右**平移**三**分之一屏..."
    * **英文:** `The shot trucks right by one-third of the screen width,`
* **中文 (旋转-俯仰):** "将镜头拍摄视角变为**俯**拍，角度为**30**°..."
    * **英文:** `The shot tilts down by 30 degrees,`
* **中文 (旋转-俯仰):** "将镜头拍摄视角变为**仰**拍，角度为**30**°..."
    * **英文:** `The shot tilts up by 30 degrees,`
* **中文 (旋转-摇镜):** "将镜头拍摄视角向**左**旋转，角度为**30**°..."
    * **英文:** `The shot pans left by 30 degrees,`
* **中文 (希区柯克):** "希区柯克变焦，背景压缩..." (或 "将焦段...使背景贴近...")
    * **英文:** `The shot dolly zooms (compressing background),`
* **中文 (希区柯K):** "希区柯克变焦，背景拉伸..." (或 "将焦段...使背景远离...")
    * **英文:** `The shot dolly zooms (expanding background),`
* **中文 (人物姿态变化):** "使画面中的人物**抬头**..." (或 "点头", "挥手" 等)
    * **英文:** `The shot is static,`

**--- Synthesis Rule (CRITICAL) ---**

* **If the motion is (Static):** Your content description should describe the **action** (e.g., "...as a person looks up at the camera.").
* **If the motion is (Pan, Tilt, Pedestal, etc.):** Your content description should describe the **static subject** (e.g., "...showing a person with brown hair standing still.").

**--- Examples (Your Goal) ---**

* **Input:**  + "CHINESE_INSTRUCTION: 镜头向上平移三分之一屏，保持俯仰不变、人物姿态不变。"
* **Your Output:** `The shot pedestals up by one-third of the screen height, focusing on a man with glasses and a beard standing still.`

* **Input:**  + "CHINESE_INSTRUCTION: 使画面中的人物抬头，使人脸直视镜头，保持人物ID不变。"
* **Your Output:** `The shot is static, as a woman with blonde hair looks up to face the camera.`

* **Input:**  + "CHINESE_INSTRUCTION: 将镜头拍摄视角变为俯拍，角度为30°，保持镜头拍摄位置不变、人物姿态不变。"
* **Your Output:** `The shot tilts down by 30 degrees, looking at a man in a red shirt who is sitting still.`

**--- Your Task ---**
You will now receive an image and a CHINESE_INSTRUCTION. Generate the single-line English prompt exactly as shown in the examples. Do not provide any other text.
"""


from transformers import Qwen3VLForConditionalGeneration, AutoProcessor

# --- 1. 定义您的 "系统" PROMPT ---
VLM_PROMPT_GENERATOR = """You are an expert prompt engineer...[此处省略，请将上面完整的prompt字符串复制到这里]...Do not provide any other text.
"""

# --- 2. 加载模型和处理器 ---
print("Loading model and processor...")
# default: Load the model on the available device(s)
model = Qwen3VLForConditionalGeneration.from_pretrained(
    "Qwen/Qwen3-VL-8B-Instruct", dtype="auto", device_map="auto"
)
processor = AutoProcessor.from_pretrained("Qwen/Qwen3-VL-8B-Instruct")
print("Model and processor loaded.")

# --- 3. 准备您的数据 ---
# !! 重要：在此处设置您的图像和对应的中文指令
image_path = "path/to/your/image_01.jpg"  # <-- 替换为您的图像路径
chinese_instruction = "镜头向上平移三分之一屏，保持俯仰不变、人物姿态不变。" # <-- 替换为对应的中文指令

# --- 4. 构建 VLM 的 messages ---
# 这是关键步骤。我们将系统指令、图像和中文指令全部放入一个 "user" turn 中。
messages = [
    {
        "role": "user",
        "content": [
            # 第一部分：VLM的 "系统指令" (规则、映射和示例)
            {
                "type": "text",
                "text": VLM_PROMPT_GENERATOR
            },
            
            # 第二部分：图像数据
            {
                "type": "image", 
                "image": image_path  # 使用您的本地图像路径
            },
            
            # 第三部分：针对此图像的 "中文指令"
            {
                "type": "text", 
                "text": f"CHINESE_INSTRUCTION: {chinese_instruction}"
            }
        ],
    }
]

# --- 5. 准备推理 ---
print(f"Processing image: {image_path} with instruction: {chinese_instruction}")
inputs = processor.apply_chat_template(
    messages,
    tokenize=True,
    add_generation_prompt=True,
    return_dict=True,
    return_tensors="pt"
)
inputs = inputs.to(model.device)

# --- 6. 生成英文 Prompt ---
print("Generating English prompt...")
generated_ids = model.generate(**inputs, max_new_tokens=128) # max_new_tokens可能需要调整
generated_ids_trimmed = [
    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
]
output_text_list = processor.batch_decode(
    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
)

# --- 7. 打印结果 ---
print("\n--- Generated English Prompt ---")
if output_text_list:
    # 打印VLM的最终输出
    print(output_text_list[0])
else:
    print("Error: No output generated.")

# 预期的输出 (示例):
# The shot pedestals up by one-third of the screen height, focusing on a [VLM对图像的描述] standing still.
