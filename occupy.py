import torch
import time
import sys

def occupy_gpu(gpu_id):
    """
    ä¸€ä¸ªå·¥ä½œå‡½æ•°ï¼Œç”¨äºæŒç»­å ç”¨å•ä¸ª GPUã€‚

    å®ƒä¼šåˆ†é… GPU æ˜¾å­˜çš„çº¦ 90%ï¼Œ
    å¹¶åœ¨ä¸€ä¸ªæ— é™å¾ªç¯ä¸­æ‰§è¡ŒçŸ©é˜µä¹˜æ³•ã€‚
    """
    
    # æ£€æŸ¥ GPU ID æ˜¯å¦æœ‰æ•ˆ
    if not (0 <= gpu_id < torch.cuda.device_count()):
        print(f"âŒ é”™è¯¯: GPU ID {gpu_id} æ— æ•ˆã€‚")
        print(f"   è¯·æä¾›ä¸€ä¸ª 0 åˆ° {torch.cuda.device_count() - 1} ä¹‹é—´çš„ IDã€‚")
        sys.exit(1)
        
    device = f'cuda:{gpu_id}'
    
    # è®¾ç½®å½“å‰è®¾å¤‡
    torch.cuda.set_device(device)
    
    print(f"âœ… [GPU {gpu_id}] å¼€å§‹å ç”¨... {torch.cuda.get_device_name(gpu_id)}")

    # åˆå§‹åŒ–ä¸¤ä¸ªå¤§å¼ é‡ä»¥å ç”¨å†…å­˜å’Œç”¨äºè®¡ç®—
    a = None
    b = None
    
    try:
        # 1. åˆ†é…æ˜¾å­˜
        # è·å–æ€»æ˜¾å­˜ï¼Œå¹¶è®¡ç®— 45% ç”¨äºæ¯ä¸ªå¼ é‡ (æ€»å…± 90%)
        total_mem = torch.cuda.get_device_properties(device).total_memory
        target_bytes_per_tensor = int(total_mem * 0.45)
        
        # float32 = 4 bytes
        num_elements = target_bytes_per_tensor // 4
        # è®¡ç®—ä¸€ä¸ªå¤§è‡´çš„æ–¹é˜µç»´åº¦
        size = int(num_elements**0.5)

        print(f"   [GPU {gpu_id}] æ€»æ˜¾å­˜: {total_mem / 1024**3:.2f} GB")
        print(f"   [GPU {gpu_id}] æ­£åœ¨åˆ†é…ä¸¤ä¸ª {size}x{size} çš„å¼ é‡ (æ¯ä¸ªçº¦ {target_bytes_per_tensor / 1024**3:.2f} GB)...")

        # åˆ†é…å¼ é‡
        a = torch.randn(size, size, device=device, dtype=torch.float32)
        b = torch.randn(size, size, device=device, dtype=torch.float32)
        
        print(f"   [GPU {gpu_id}] æ˜¾å­˜åˆ†é…å®Œæˆã€‚å¼€å§‹è®¡ç®—å¾ªç¯...")

        # 2. æŒç»­è®¡ç®—
        while True:
            # æ‰§è¡Œä¸€ä¸ªé«˜å¼ºåº¦æ“ä½œ
            a = torch.add(a, 0.001) # åšä¸€ç‚¹å°è®¡ç®—
            b = torch.add(b, 0.001)
            c = torch.matmul(a, b) # æ ¸å¿ƒè®¡ç®—

    except KeyboardInterrupt:
        # æ•è· Ctrl+C
        print(f"\nğŸ›‘ [GPU {gpu_id}] æ”¶åˆ°åœæ­¢ä¿¡å·ã€‚æ­£åœ¨é‡Šæ”¾...")
        
    except RuntimeError as e:
        # æ•è·å¯èƒ½çš„ OOM (Out of Memory) é”™è¯¯
        if "out of memory" in str(e):
            print(f"\nâŒ [GPU {gpu_id}] æ˜¾å­˜ä¸è¶³ (OOM)ï¼å°è¯•åˆ†é…çš„å¼ é‡å¤ªå¤§ã€‚")
            print("   [GPU {gpu_id}] è¯·å°è¯•å‡å° '0.45' (45%) è¿™ä¸ªæ¯”ä¾‹ã€‚")
        else:
            print(f"\nâŒ [GPU {gpu_id}] å‘ç”Ÿè¿è¡Œæ—¶é”™è¯¯: {e}")
            
    finally:
        # æ— è®ºå¦‚ä½•ï¼Œéƒ½å°è¯•æ¸…ç†èµ„æº
        if a is not None:
            del a
        if b is not None:
            del b
        
        torch.cuda.empty_cache()
        print(f"ğŸ“‰ [GPU {gpu_id}] æ˜¾å­˜å·²é‡Šæ”¾ã€‚")

def main():
    # ç¡®ä¿ CUDA å¯ç”¨
    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯: CUDA ä¸å¯ç”¨ã€‚è¯·æ£€æŸ¥æ‚¨çš„ PyTorch å’Œ CUDA é©±åŠ¨ã€‚")
        sys.exit(1)

    # ä»å‘½ä»¤è¡Œå‚æ•°è·å– GPU ID
    if len(sys.argv) != 2:
        print("âŒ é”™è¯¯: ä½¿ç”¨æ–¹æ³•: python occupy_single_gpu.py <gpu_id>")
        print("   ä¾‹å¦‚: python occupy_single_gpu.py 0")
        sys.exit(1)
        
    try:
        gpu_id = int(sys.argv[1])
    except ValueError:
        print(f"âŒ é”™è¯¯: GPU ID '{sys.argv[1]}' å¿…é¡»æ˜¯ä¸€ä¸ªæ•´æ•°ã€‚")
        sys.exit(1)
        
    # è¿è¡Œå ç”¨å‡½æ•°
    occupy_gpu(gpu_id)

if __name__ == "__main__":
    main()